{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FlaskApp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simonsny/image_background_removal/blob/dev_simon/FlaskApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2gyuRc6cQ7N"
      },
      "source": [
        "Connecting Google Colab to your Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyoPTWT1cSg9",
        "outputId": "4df130c2-f174-449a-8a4f-e24c5b1f8e70"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niHkRngUcYiv"
      },
      "source": [
        "Installing the Flask-ngrok to be able to run the Flask app\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paoNutB-qSbF",
        "outputId": "f28e4965-93c3-402f-9ea1-4976e121065d"
      },
      "source": [
        "\n",
        "!pip install flask-ngrok \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87NjXbh8cbVY"
      },
      "source": [
        "Importing the necessary packages to run the program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9_0gN0HNQ-e"
      },
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn\n",
        "from torchvision import transforms, utils\n",
        "from tqdm import tqdm\n",
        "from skimage import io, transform, color\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from __future__ import print_function, division\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmksQX4DNv39"
      },
      "source": [
        "Getting the inference from U2Net to get the alpha matte which we will use as a binary mask to get the trimap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LGIzFGyvjOf",
        "outputId": "afae7db8-b8b7-466a-9d48-0ab413ca31b7"
      },
      "source": [
        "import os\n",
        "from skimage import io, transform\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms#, utils\n",
        "# import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "%cd /content/drive/MyDrive/BeCode/Faktion/U-2-Net/\n",
        "from data_loader import RescaleT\n",
        "from data_loader import ToTensor\n",
        "from data_loader import ToTensorLab\n",
        "from data_loader import SalObjDataset\n",
        "\n",
        "from model import U2NET # full size version 173.6 MB\n",
        "from model import U2NETP # small version u2net 4.7 MB\n",
        "\n",
        "# normalize the predicted SOD probability map\n",
        "def normPRED(d):\n",
        "    ma = torch.max(d)\n",
        "    mi = torch.min(d)\n",
        "\n",
        "    dn = (d-mi)/(ma-mi)\n",
        "\n",
        "    return dn\n",
        "\n",
        "def save_output(image_name,pred,d_dir):\n",
        "\n",
        "    predict = pred\n",
        "    predict = predict.squeeze()\n",
        "    predict_np = predict.cpu().data.numpy()\n",
        "\n",
        "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
        "    img_name = image_name.split(os.sep)[-1]\n",
        "    image = io.imread(image_name)\n",
        "    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
        "\n",
        "    pb_np = np.array(imo)\n",
        "\n",
        "    aaa = img_name.split(\".\")\n",
        "    bbb = aaa[0:-1]\n",
        "    imidx = bbb[0]\n",
        "    for i in range(1,len(bbb)):\n",
        "        imidx = imidx + \".\" + bbb[i]\n",
        "\n",
        "    imo.save(d_dir+imidx+'.png')\n",
        "\n",
        "def u2net(filename):\n",
        "    \n",
        "    %cd /content/drive/MyDrive/BeCode/Faktion/U-2-Net/\n",
        "\n",
        "    # --------- 1. get image path and name ---------\n",
        "    model_name='u2net'#u2netp\n",
        "\n",
        "    \"\"\"\n",
        "    image_dir = os.path.join(os.getcwd(), 'test_data', 'test_images')\n",
        "    prediction_dir = os.path.join(os.getcwd(), 'test_data', model_name + '_results' + os.sep)\n",
        "    model_dir = os.path.join(os.getcwd(), 'saved_models', model_name, model_name + '.pth')\n",
        "    \"\"\"\n",
        "    image_dir = filename\n",
        "    #image_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/uploads/'\n",
        "    prediction_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/binary_mask/'\n",
        "    model_dir =  '/content/drive/MyDrive/BeCode/Faktion/U-2-Net/saved_models/u2net/u2net.pth'\n",
        "\n",
        "\n",
        "    img_name_list = [filename.split(\"/\")[-1]]\n",
        "    print(img_name_list)\n",
        "\n",
        "\n",
        "    %cd '/content/drive/MyDrive/BeCode/Faktion/Flask/static/uploads/' \n",
        "    # --------- 2. dataloader ---------\n",
        "    #1. dataloader\n",
        "    test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,\n",
        "                                        lbl_name_list = [],\n",
        "                                        transform=transforms.Compose([RescaleT(320),\n",
        "                                                                      ToTensorLab(flag=0)])\n",
        "                                        )\n",
        "    test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
        "                                        batch_size=1,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=1)\n",
        "\n",
        "    # --------- 3. model define ---------\n",
        "    if(model_name=='u2net'):\n",
        "        print(\"...load U2NET---173.6 MB\")\n",
        "        net = U2NET(3,1)\n",
        "    elif(model_name=='u2netp'):\n",
        "        print(\"...load U2NEP---4.7 MB\")\n",
        "        net = U2NETP(3,1)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        net.load_state_dict(torch.load(model_dir))\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.load_state_dict(torch.load(model_dir, map_location='cpu'))\n",
        "    net.eval()\n",
        "\n",
        "    # --------- 4. inference for each image ---------\n",
        "    for i_test, data_test in enumerate(test_salobj_dataloader):\n",
        "\n",
        "        print(\"inferencing:\",img_name_list[i_test].split(os.sep)[-1])\n",
        "\n",
        "        inputs_test = data_test['image']\n",
        "        inputs_test = inputs_test.type(torch.FloatTensor)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            inputs_test = Variable(inputs_test.cuda())\n",
        "        else:\n",
        "            inputs_test = Variable(inputs_test)\n",
        "\n",
        "        d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
        "\n",
        "        # normalization\n",
        "        pred = d1[:,0,:,:]\n",
        "        pred = normPRED(pred)\n",
        "\n",
        "        # save results to test_results folder\n",
        "        if not os.path.exists(prediction_dir):\n",
        "            os.makedirs(prediction_dir, exist_ok=True)\n",
        "        save_output(img_name_list[i_test],pred,prediction_dir)\n",
        "\n",
        "        del d1,d2,d3,d4,d5,d6,d7\n",
        "\n",
        "    print(\"Successfully created the binary mask\")\n",
        "    return filename.split(\".\")[0] + \".png\"\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1q6pqWmSu1bY-mc2AFRwGmQIGMV0sa6EY/BeCode/Faktion/U-2-Net\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dslFdPM-2J7K"
      },
      "source": [
        "Generate the trimap using the U2net mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIU--dpmNTab"
      },
      "source": [
        "import cv2\n",
        "\"\"\"\n",
        "def generate_trimap(mask_path,eroision_iter=3,dilate_iter=6):\n",
        "    mask =  mask_path\n",
        "    mask = cv2.imread(mask,0)\n",
        "    mask[mask==1] = 255\n",
        "    d_kernel = np.ones((3,3))\n",
        "    erode  = cv2.erode(mask,d_kernel,iterations=eroision_iter)\n",
        "    dilate = cv2.dilate(mask,d_kernel,iterations=dilate_iter)\n",
        "    unknown1 = cv2.bitwise_xor(erode,mask)\n",
        "    unknown2 = cv2.bitwise_xor(dilate,mask)\n",
        "    unknowns = cv2.add(unknown1,unknown2)\n",
        "    unknowns[unknowns==255]=127\n",
        "    trimap = cv2.add(mask,unknowns)\n",
        "    cv2.imwrite(f\"/content/drive/MyDrive/BeCode/Faktion/Flask/static/trimap/{mask_path.split('/')[-1]}\",trimap)\n",
        "    return mask_path.split('/')[-1]\n",
        "    \"\"\"\n",
        "\n",
        "# Trying out Simon's Trimap code again :)\n",
        "\n",
        "def generate_trimap(mask_path,eroision_iter=2,dilate_iter=4):\n",
        "    mask =  mask_path\n",
        "    mask = cv2.imread(mask,0)\n",
        "    mask[mask >= 20] = 255\n",
        "    mask[mask < 20] = 0\n",
        "    d_kernel = np.ones((3,3))\n",
        "    erode  = cv2.erode(mask,d_kernel,iterations=eroision_iter)\n",
        "    dilate = cv2.dilate(mask,d_kernel,iterations=dilate_iter)\n",
        "\n",
        "    gray = (dilate-erode)/2\n",
        "    trimap = erode + gray\n",
        "    cv2.imwrite(f\"/content/drive/MyDrive/BeCode/Faktion/Flask/static/trimap/{mask_path.split('/')[-1]}\",trimap)\n",
        "    return mask_path.split('/')[-1]\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isbIcoTcFcAJ"
      },
      "source": [
        "Generate the Alpha Matte using DIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpvwuKaxNU6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a418e1e7-4451-45b5-d8ce-5f95872da3d8"
      },
      "source": [
        "from torchvision import transforms\n",
        "%cd /content/drive/MyDrive/Faktion/model_code\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # sets device for model and PyTorch tensors\n",
        "\n",
        "def alpha_matte(file):\n",
        "  %cd /content/drive/MyDrive/BeCode/Faktion/model_code/\n",
        "  IMG_FOLDER = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/uploads/'\n",
        "  TRIMAP_FOLDER = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/trimap/'\n",
        "  matte_folder = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/matte/'\n",
        "  print(\"Alpha Matte Function\")\n",
        "  checkpoint = '/content/drive/MyDrive/BeCode/Faktion/BEST_checkpoint.tar'\n",
        "  checkpoint = torch.load(checkpoint)\n",
        "  model = checkpoint['model'].module\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  print('DIM Model Eval')\n",
        "\n",
        "  filename = os.path.join(IMG_FOLDER, file)\n",
        "  img = cv.imread(filename)\n",
        "  print(img.shape)\n",
        "  h, w = img.shape[:2]\n",
        "\n",
        "\n",
        "  x = torch.zeros((1, 4, h, w), dtype=torch.float)\n",
        "  image = img[..., ::-1]  # RGB\n",
        "  image = transforms.ToPILImage()(image)\n",
        "\n",
        "  transformer = transforms.Compose(\n",
        "      [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  image = transformer(image)\n",
        "  x[0:, 0:3, :, :] = image\n",
        "\n",
        "  filename = os.path.join(TRIMAP_FOLDER, file.replace('.jpg', '.png'))\n",
        "  print(f'Reading trimap: {filename}...')\n",
        "  trimap = cv.imread(filename, 0)\n",
        "  \n",
        "  x[0:, 3, :, :] = torch.from_numpy(trimap.copy() / 255.)\n",
        "  \n",
        "  # Move to GPU, if available\n",
        "  x = x.type(torch.FloatTensor).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      pred = model(x)\n",
        "\n",
        "  pred = pred.cpu().numpy()\n",
        "  pred = pred.reshape((h, w))\n",
        "\n",
        "  pred[trimap == 0] = 0.0\n",
        "  pred[trimap == 255] = 1.0\n",
        "\n",
        "  out = (pred.copy() * 255).astype(np.uint8)\n",
        "\n",
        "  #filename = os.path.join(OUTPUT_FOLDERS[i], file)\n",
        "  #cv.imread(filename)\n",
        "  cv.imwrite(matte_folder+file.replace('.jpg', '.png'), out)\n",
        "  print(f'Created an alpha matte for  {file}.'.format(filename))\n",
        "  return matte_folder + file.replace('.jpg', '.png')\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1pbfU2Nkn_OKUrAgN_cnPqhS91KoSQBr8/Faktion/model_code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aNI65Fgcf-O"
      },
      "source": [
        "Getting the foreground image using the original image and the alpha matte.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1rrTaBTciFM"
      },
      "source": [
        "def foreground_image(image, matte, filename):\n",
        "  print(f'Image name: {filename}')\n",
        "  # obtain predicted foreground\n",
        "  output_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/output/'\n",
        "  image = np.asarray(image)\n",
        "  if len(image.shape) == 2:\n",
        "    image = image[:, :, None]\n",
        "  if image.shape[2] == 1:\n",
        "    image = np.repeat(image, 3, axis=2)\n",
        "  elif image.shape[2] == 4:\n",
        "    image = image[:, :, 0:3]\n",
        "  matte = np.repeat(np.asarray(matte)[:, :, None], 3, axis=2) / 255\n",
        "  foreground = image * matte + np.full(image.shape, 255) * (1 - matte)\n",
        "  \n",
        "  foreground_name = filename.split('.')[0] + '.png'\n",
        "  Image.fromarray(((foreground).astype('uint8')), mode='L').save(os.path.join(outpur_dir, foreground_name))\n",
        "  print(f\"Successfully saved the foreground image {foreground_name}\")\n",
        "  return foreground_name\n",
        "\n",
        "\n",
        "def foreground_img(image, alpha, filename):\n",
        "  # Read the images\n",
        "  img = cv2.imread(image)\n",
        "  matte = cv2.imread(alpha)\n",
        "\n",
        "  # Convert uint8 to float\n",
        "  img = img.astype(float)\n",
        "\n",
        "  # Normalize the alpha matte mask to keep intensity between 0 and 1\n",
        "  matte = matte.astype(float)/255\n",
        "\n",
        "  # Multiply the foreground with the alpha matte\n",
        "  foreground = cv2.multiply(matte, img)\n",
        "\n",
        "  # Save image\n",
        "  cv2.imwrite(output_dir+filename.replace('.jpg', '.png'),  foreground)\n",
        "  print(f\"Successfully saved the foreground image for {filename}.\")\n",
        "  return filename"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OoaxQJNcjeh"
      },
      "source": [
        "Flask Application starts here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDP64lno2N3b",
        "outputId": "e1e54dcd-3512-4f77-ace4-52dc57f0dad4"
      },
      "source": [
        "import os\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, flash, render_template, request, redirect, url_for, send_file\n",
        "import time\n",
        "from werkzeug.utils import secure_filename\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\"\"\"\n",
        ":attrib upload_dir contains the upload path of the uploaded image\n",
        ":attrib output_dir contains the output/result image \n",
        ":attrib matte_dir contains the alpha matte of the image\n",
        ":allowed_extensions contains the list of allowed image file extensions\n",
        "\"\"\"\n",
        "upload_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/uploads/'\n",
        "output_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/output/'\n",
        "matte_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/matte/'\n",
        "trimap_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/trimap/'\n",
        "binary_dir = '/content/drive/MyDrive/BeCode/Faktion/Flask/static/binary_mask/'\n",
        "allowed_extensions = {\"png\", \"jpg\", \"jpeg\", \"gif\"}\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/drive/MyDrive/BeCode/Faktion/Flask/templates/', static_folder='/content/drive/MyDrive/BeCode/Faktion/Flask/static')\n",
        "run_with_ngrok(app)\n",
        "app.secret_key = \"secret key\"\n",
        "app.config[\"UPLOAD_FOLDER\"] = upload_dir\n",
        "\n",
        "def allowed_file(filename):\n",
        "    \"\"\"\n",
        "    Function that checks the file extensions is included on the allowed list.\n",
        "    \"\"\"\n",
        "    return \".\" in filename and filename.rsplit(\".\", 1)[1].lower() in allowed_extensions\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    \"\"\"\n",
        "    Function that returns the home page.\n",
        "    \"\"\"\n",
        "    return render_template(\"home.html\")\n",
        "\n",
        "@app.route(\"/start\", methods=[\"GET\", \"POST\"])\n",
        "def start():\n",
        "    \"\"\"\n",
        "    Function that has both GET and POST method.\n",
        "    This is the function where it will ask the user input and \n",
        "    then return the input with the edited version of the input\n",
        "    \"\"\"\n",
        "    if request.method == \"GET\":\n",
        "        return render_template(\"start.html\")\n",
        "\n",
        "    if request.method == \"POST\":\n",
        "        if \"image\" not in request.files and \"video\" not in request.files:\n",
        "            return redirect(request.url)\n",
        "        \"\"\"\n",
        "        :attrib image will contain the image user input \n",
        "        :attrib video will contain the video user input\n",
        "        :attrib start will contain the start time on when the program started\n",
        "        :attrib end will contain the end time on when the program ended\n",
        "        \"\"\"\n",
        "        image = request.files.get(\"image\")\n",
        "        print(f\"Image Input: {image}\")\n",
        "        video = request.files.get(\"video\")\n",
        "        print(f\"Video Input: {video}\")\n",
        "        start = time.time()\n",
        "\n",
        "        if image == \"\" and video == \"\":\n",
        "            return redirect(request.url)\n",
        "\n",
        "        elif image:\n",
        "            print(\"Elif image file\")\n",
        "            if allowed_file(image.filename):\n",
        "                image_upload = secure_filename(image.filename)\n",
        "                image.save(os.path.join(app.config[\"UPLOAD_FOLDER\"], image_upload))\n",
        "                #calling the function to create the alpha matte\n",
        "                #matte_name = image_ckpt(image_upload)\n",
        "\n",
        "                #get the binary mask using U2Net\n",
        "                binary_mask = u2net(image_upload)\n",
        "\n",
        "\n",
        "                \n",
        "                #generate trimap using binary mask\n",
        "                trimap = generate_trimap(binary_dir + binary_mask)\n",
        "                #trimap = gen_trimap(binary_dir + binary_mask)\n",
        "                #get the alpha matte which needs image and trimap\n",
        "                matte_name = alpha_matte(image.filename)\n",
        "\n",
        "                #calling the function to create the foreground image\n",
        "                #img_path = Image.open(os.path.join(upload_dir, image.filename))\n",
        "                #matte_path = Image.open(os.path.join(matte_dir, matte_name))\n",
        "\n",
        "                image_path = upload_dir + image.filename\n",
        "                print(f'Image Path: {image_path}')\n",
        "                print(f'Binary Mask Path: {binary_dir + binary_mask}')\n",
        "                #print(f'Trimap Path: {trimap_dir +trimap}')\n",
        "                print(f'Alpha Matte Path: {matte_name}')\n",
        "\n",
        "\n",
        "                edited_image = foreground_img(image_path, matte_name, image.filename)\n",
        "                print(f'Edited Image: {edited_image}')\n",
        "                foreground = Image.open(os.path.join(output_dir, edited_image))\n",
        "\n",
        "\n",
        "                end = time.time()\n",
        "                print(f\"Program runs for {end - start} seconds.\")\n",
        "                return render_template(\"upload_image.html\", filename=image_upload)\n",
        "            else:\n",
        "                flash(\"Chosen file is not supported! Please upload an image file.\")\n",
        "                flash(\"Allowed image types are -> png, jpg, jpeg, gif\")\n",
        "                return redirect(request.url)\n",
        "\n",
        "        elif video:\n",
        "            print(\"Elif video file\")\n",
        "            end = time.time()\n",
        "            print(f\"Program runs for {end - start} seconds.\")\n",
        "            return render_template(\"home.html\")\n",
        "\n",
        "        else:\n",
        "            return render_template(\"start.html\")\n",
        "\n",
        "@app.route(\"/display/<filename>\")\n",
        "def display_image(filename):\n",
        "    \"\"\"\n",
        "    Function that displays the uploaded image.\n",
        "    \"\"\"\n",
        "    print(f\"Display image : {filename}\")\n",
        "    return redirect(url_for(\"static\", filename=\"uploads/\" + filename), code=301)\n",
        "    \n",
        "@app.route(\"/edited/<filename>\")\n",
        "def edited_image(filename):\n",
        "    \"\"\"\n",
        "    Function that displayes the edited image/result image.\n",
        "    \"\"\"\n",
        "    file = filename.replace('.jpg', '.png')\n",
        "    print(f\"Edited image : {file}\")\n",
        "    return redirect(url_for(\"static\", filename=\"output/\" + file), code=301)\n",
        "\n",
        "@app.route(\"/save_file/<filename>\")\n",
        "def save_file(filename):\n",
        "    \"\"\"\n",
        "    Function that that allows the user to save/download the image.\n",
        "    \"\"\"\n",
        "    path = f\"/content/drive/MyDrive/BeCode/Faktion/Flask/static/output/{filename.replace('.jpg', '.png')}\"\n",
        "    print(f\"Send File Path: {path}\")\n",
        "    return send_file(path, as_attachment=True)\n",
        "\n",
        "@app.route(\"/upload_image\")\n",
        "def upload_image():\n",
        "    \"\"\"\n",
        "    Function that returns the upload_image page.\n",
        "    \"\"\"\n",
        "    return render_template(\"upload_image.html\")\n",
        "\n",
        "@app.route(\"/howtouse\")\n",
        "def howtouse():\n",
        "    \"\"\"\n",
        "    Function that returns the how to use page.\n",
        "    \"\"\"\n",
        "    return render_template(\"howtouse.html\")\n",
        "\n",
        "@app.route(\"/about\")\n",
        "def about():\n",
        "    \"\"\"\n",
        "    Function that returns the about page.\n",
        "    \"\"\"\n",
        "    return render_template(\"about.html\")\n",
        "\n",
        "@app.route(\"/live_feed\")\n",
        "def live_feed():\n",
        "    \"\"\"\n",
        "    Function that returns the live feed page.\n",
        "    \"\"\"\n",
        "    return render_template(\"live_feed.html\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://09e4c0f0141f.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Jun/2021 16:40:06] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:07] \"\u001b[37mGET /static/assets/logo4.png HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:07] \"\u001b[37mGET /static/assets/cover.png HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:07] \"\u001b[37mGET /static/assets/remove.png HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:07] \"\u001b[37mGET /static/assets/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:08] \"\u001b[37mGET /start HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image Input: <FileStorage: 'ILSVRC2012_test_00000181.jpg' ('image/jpeg')>\n",
            "Video Input: None\n",
            "Elif image file\n",
            "/content/drive/.shortcut-targets-by-id/1q6pqWmSu1bY-mc2AFRwGmQIGMV0sa6EY/BeCode/Faktion/U-2-Net\n",
            "['ILSVRC2012_test_00000181.jpg']\n",
            "/content/drive/.shortcut-targets-by-id/1q6pqWmSu1bY-mc2AFRwGmQIGMV0sa6EY/BeCode/Faktion/Flask/static/uploads\n",
            "...load U2NET---173.6 MB\n",
            "inferencing: ILSVRC2012_test_00000181.jpg\n",
            "Successfully created the binary mask\n",
            "/content/drive/.shortcut-targets-by-id/1q6pqWmSu1bY-mc2AFRwGmQIGMV0sa6EY/BeCode/Faktion/model_code\n",
            "Alpha Matte Function\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.parallel.data_parallel.DataParallel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxUnpool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:15] \"\u001b[37mPOST /start HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DIM Model Eval\n",
            "(397, 400, 3)\n",
            "Reading trimap: /content/drive/MyDrive/BeCode/Faktion/Flask/static/trimap/ILSVRC2012_test_00000181.png...\n",
            "Created an alpha matte for  ILSVRC2012_test_00000181.jpg.\n",
            "Image Path: /content/drive/MyDrive/BeCode/Faktion/Flask/static/uploads/ILSVRC2012_test_00000181.jpg\n",
            "Binary Mask Path: /content/drive/MyDrive/BeCode/Faktion/Flask/static/binary_mask/ILSVRC2012_test_00000181.png\n",
            "Alpha Matte Path: /content/drive/MyDrive/BeCode/Faktion/Flask/static/matte/ILSVRC2012_test_00000181.png\n",
            "Successfully saved the foreground image for ILSVRC2012_test_00000181.jpg.\n",
            "Edited Image: ILSVRC2012_test_00000181.jpg\n",
            "Program runs for 1.5996310710906982 seconds.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Jun/2021 16:40:15] \"\u001b[32mGET /display/ILSVRC2012_test_00000181.jpg HTTP/1.1\u001b[0m\" 301 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Display image : ILSVRC2012_test_00000181.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Jun/2021 16:40:15] \"\u001b[37mGET /static/uploads/ILSVRC2012_test_00000181.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:15] \"\u001b[32mGET /edited/ILSVRC2012_test_00000181.jpg HTTP/1.1\u001b[0m\" 301 -\n",
            "127.0.0.1 - - [09/Jun/2021 16:40:15] \"\u001b[37mGET /static/output/ILSVRC2012_test_00000181.png HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Edited image : ILSVRC2012_test_00000181.png\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}